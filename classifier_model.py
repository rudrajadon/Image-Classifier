# -*- coding: utf-8 -*-
"""
classifier_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RYu5HfMj_g1sXZZonJIRgOuExFb7aSum
"""

from google.colab import drive
drive.mount('/content/drive')

"""###Setup and Training"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import RMSprop
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import os
from keras.preprocessing import image

# Define paths to your training and validation data
train_dir = '/content/drive/My Drive/AI_Real/Train_Images'
validation_dir = '/content/drive/My Drive/AI_Real/Validation_Images'

# Create ImageDataGenerator instances for training and validation data
train_datagen = ImageDataGenerator(rescale=1/255)
validation_datagen = ImageDataGenerator(rescale=1/255)

# Generate batches of augmented data for training and validation
train_dataset = train_datagen.flow_from_directory(
    train_dir,
    target_size=(200, 200),
    batch_size=16,
    class_mode='binary'
)

validation_dataset = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(200, 200),
    batch_size=16,
    class_mode='binary'
)

train_dataset.class_indices

validation_dataset.class_indices

"""###Model Definition and Compilation"""

# Define the CNN model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(200, 200, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(learning_rate=0.001),
              metrics=['accuracy'])

# Train the model
model_fit = model.fit(train_dataset,
                      steps_per_epoch = 10,
                      epochs = 100,
                      validation_data = validation_dataset)

"""###Evaluating the model"""

# Directory containing test images
dir_path = "/content/drive/My Drive/AI_Real/Test_Images"

# Predict and display images from the test directory
for i in os.listdir(dir_path):
        img = image.load_img(dir_path+'//'+i,target_size=(200,200))
        plt.imshow(img)
        plt.show()

        X = image.img_to_array(img)
        X = np.expand_dims(X,axis = 0)
        images = np.vstack([X])
        val = model.predict(images)
        if val < 0.5:
            plt.title("AI")
            print(val)
        else:
            plt.title("Real")
            print(val)

print("Prediction completed.")

# Save the model to Google Drive
model.save('/content/drive/My Drive/trained_model.h5', include_optimizer=False)
print("Model saved to Google Drive.")